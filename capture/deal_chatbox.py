# åœ¨åŸæœ‰å¯¼å…¥éƒ¨åˆ†æ–°å¢
import os
import time
from pprint import pprint

import pyautogui

from Constants import Constants
from .window_manager import fget_window_manager

# ç”µè„‘ç‰ˆå¾®ä¿¡å…¨å±çŠ¶æ€çš„çª—å£åŒºåŸŸï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
WECHAT_WINDOW = Constants.WECHAT_WINDOW
import easyocr
OCR_READER = easyocr.Reader(['ch_sim', 'en'], gpu=True)  # æ·»åŠ gpu=Trueå‚æ•°å¯ç”¨GPUåŠ é€Ÿ


def fextract_text_by_color_flow(image,target_color , tolerance=1):
    """
    ä¿®æ”¹è¯´æ˜ï¼š
    1. å¢åŠ åŒºåŸŸå‚ç›´ä½ç½®åˆ¤æ–­é€»è¾‘
    2. è¿”å›æœ€ä¸‹æ–¹ç¬¦åˆæ¡ä»¶çš„æ–‡æœ¬åŒºåŸŸ
    """
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    lower = np.array([max(0, c - tolerance) for c in target_color])
    upper = np.array([min(255, c + tolerance) for c in target_color])
    mask = cv2.inRange(image, lower, upper)

    # ä¼˜åŒ–è½®å»“æŸ¥æ‰¾å‚æ•°
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    max_bottom = -1
    target_contour = None

    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        current_bottom = y + h  # è®¡ç®—åŒºåŸŸåº•éƒ¨Yåæ ‡

        # è¿‡æ»¤è¿‡å°åŒºåŸŸï¼ˆæ ¹æ®å®é™…åœºæ™¯è°ƒæ•´ï¼‰
        if w > 50 and h > 20:  # å¢åŠ æœ€å°å®½é«˜é™åˆ¶
            if current_bottom > max_bottom:
                max_bottom = current_bottom
                target_contour = (x, y, w, h)

    return target_contour if target_contour is not None else (0, 0, 0, 0)


import cv2
import numpy as np

# é¢„å®šä¹‰å¸¸é‡ï¼ˆæ ¹æ®å®é™…åœºæ™¯æ ¡å‡†ï¼‰
GREEN_LOWER = np.array([117, 229, 164])  # BGRé¢œè‰²ä¸‹é™
GREEN_UPPER = np.array([127, 239, 174])  # BGRé¢œè‰²ä¸Šé™
X_START = 320  # æ°´å¹³èµ·å§‹åæ ‡
X_END = 1469  # æ°´å¹³ç»ˆæ­¢åæ ‡
MIN_Y = 43  # å‚ç›´æ–¹å‘æœ€å°æ£€æµ‹èµ·ç‚¹
ROI_HEIGHT = 800  # æ„Ÿå…´è¶£åŒºåŸŸé«˜åº¦


def frecognize_green_bottom(image_path):
    """
    æ€§èƒ½ä¼˜åŒ–ç‰ˆç»¿è‰²åŒºåŸŸåº•éƒ¨æ£€æµ‹
    è¿”å›ï¼šæœ€ä¸‹æ–¹ç»¿è‰²åŒºåŸŸçš„åº•éƒ¨Yåæ ‡ï¼ˆå…¨å±€åæ ‡ç³»ï¼‰ï¼Œæœªæ£€æµ‹åˆ°è¿”å›None
    """
    # é—ªç”µåŠ è½½å›¾åƒï¼ˆç°åº¦æ¨¡å¼æå‡è¯»å–é€Ÿåº¦ï¼‰
    image = cv2.imread(image_path, cv2.IMREAD_COLOR)
    if image is None:
        return None

    try:
        # ROIåŒºåŸŸè£å‰ªï¼ˆå‡å°‘å¤„ç†é¢ç§¯ï¼‰
        h, w = image.shape[:2]
        roi_y1 = max(MIN_Y, 0)
        roi_y2 = min(roi_y1 + ROI_HEIGHT, h)

        # äºŒæ¬¡æ ¡éªŒé˜²æ­¢è¶Šç•Œ
        if roi_y1 >= h or X_END >= w:
            return None

        roi = image[roi_y1:roi_y2, X_START:X_END]

        # å¿«é€Ÿé¢œè‰²é˜ˆå€¼å¤„ç†
        mask = cv2.inRange(roi, GREEN_LOWER, GREEN_UPPER)

        # å‚ç›´æ–¹å‘æŠ•å½±åˆ†æ
        vertical_projection = np.any(mask, axis=1)
        y_coords = np.where(vertical_projection)[0]

        if y_coords.size == 0:
            return None

        # è®¡ç®—å…¨å±€åæ ‡ç³»Yåæ ‡
        bottom_in_roi = y_coords[-1]  # ROIå†…çš„ç›¸å¯¹Yåæ ‡
        global_y = roi_y1 + bottom_in_roi

        # æœ‰æ•ˆæ€§éªŒè¯
        if global_y > h:
            return None

        return int(global_y)

    except Exception as e:
        print(f"æ£€æµ‹å¼‚å¸¸: {str(e)}")
        return None

# å†…å­˜ç¼“å­˜ä¼˜åŒ–ï¼ˆå‡å°‘ç£ç›˜IOï¼‰
from io import BytesIO

def fget_message_area_screenshot_bytes(use_dynamic_detection=True):
    """è·å–æ¶ˆæ¯åŒºåŸŸæˆªå›¾å¹¶è¿”å›BytesIOå¯¹è±¡"""
    # ä½¿ç”¨åŠ¨æ€çª—å£æ£€æµ‹è·å–å½“å‰çª—å£åæ ‡
    if use_dynamic_detection:
        try:
            window_manager = fget_window_manager(use_dynamic=True)
            window_coords = window_manager.get_wechat_window()
            
            # åŸºäºåŠ¨æ€çª—å£è®¡ç®—æ¶ˆæ¯åŒºåŸŸ
            msg_area = (
                window_coords[0] + 304,  # å·¦è¾¹è·ï¼ˆå¾®ä¿¡å·¦ä¾§æ å®½åº¦ï¼‰
                window_coords[1],        # é¡¶éƒ¨å¯¹é½
                window_coords[2] - 304,  # å®½åº¦å‡å»å·¦ä¾§æ 
                min(800, window_coords[3])  # é«˜åº¦é™åˆ¶æˆ–çª—å£é«˜åº¦
            )
        except Exception as e:
            print(f"âŒ åŠ¨æ€æ£€æµ‹å¤±è´¥: {e}ï¼Œå›é€€åˆ°é™æ€åæ ‡")
            # å›é€€åˆ°é™æ€åæ ‡
            msg_area = (
                WECHAT_WINDOW[0] + 304,
                WECHAT_WINDOW[1],
                1175,  # ä¿®æ­£å®½åº¦ (1479-304)
                800
            )
    else:
        # ä½¿ç”¨é™æ€åæ ‡
        msg_area = (
            WECHAT_WINDOW[0] + 304,
            WECHAT_WINDOW[1],
            1175,  # ä¿®æ­£å®½åº¦
            800
        )
    
    screenshot = pyautogui.screenshot(region=msg_area)
    # ç›´æ¥è¿”å›BytesIOå¯¹è±¡ä¾›åç»­å¤„ç†
    img_byte_arr = BytesIO()
    screenshot.save(img_byte_arr, format='PNG')
    img_byte_arr.seek(0)
    return img_byte_arr

def fget_message_area_screenshot(use_dynamic_detection=True):
    """è·å–æ¶ˆæ¯åŒºåŸŸæˆªå›¾ï¼Œæ”¯æŒåŠ¨æ€çª—å£æ£€æµ‹"""
    # ä½¿ç”¨åŠ¨æ€çª—å£æ£€æµ‹è·å–å½“å‰çª—å£åæ ‡
    if use_dynamic_detection:
        try:
            window_manager = fget_window_manager(use_dynamic=True)
            window_coords = window_manager.get_wechat_window()
            
            # åŸºäºåŠ¨æ€çª—å£è®¡ç®—æ¶ˆæ¯åŒºåŸŸ
            msg_area = (
                window_coords[0] + 304,  # å·¦è¾¹è·ï¼ˆå¾®ä¿¡å·¦ä¾§æ å®½åº¦ï¼‰
                window_coords[1],        # é¡¶éƒ¨å¯¹é½
                window_coords[2] - 304,  # å®½åº¦å‡å»å·¦ä¾§æ 
                min(800, window_coords[3])  # é«˜åº¦é™åˆ¶æˆ–çª—å£é«˜åº¦
            )
            print(f"ğŸ” åŠ¨æ€æ¶ˆæ¯åŒºåŸŸ: {msg_area}")
        except Exception as e:
            print(f"âŒ åŠ¨æ€æ£€æµ‹å¤±è´¥: {e}ï¼Œå›é€€åˆ°é™æ€åæ ‡")
            # å›é€€åˆ°é™æ€åæ ‡
            msg_area = (
                WECHAT_WINDOW[0] + 304,
                WECHAT_WINDOW[1],
                1175,  # ä¿®æ­£å®½åº¦ (1479-304)
                800
            )
    else:
        # ä½¿ç”¨é™æ€åæ ‡
        msg_area = (
            WECHAT_WINDOW[0] + 304,
            WECHAT_WINDOW[1],
            1175,  # ä¿®æ­£å®½åº¦
            800
        )
    
    os.makedirs(Constants.MESSAGES_DIR, exist_ok=True)

    screenshot = pyautogui.screenshot(region=msg_area)
    # ç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶å
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    screenshot_path = os.path.join(
        Constants.MESSAGES_DIR,
        f"{Constants.MESSAGE_PREFIX}{timestamp}.png"
    )
    screenshot.save(screenshot_path)
    return screenshot_path

def fpreprocess_for_ocr(image):
    """OCRé¢„å¤„ç†ç®¡é“"""
    # ç°åº¦åŒ–
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # è‡ªé€‚åº”é˜ˆå€¼äºŒå€¼åŒ–
    thresh = cv2.adaptiveThreshold(gray, 255,
                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                  cv2.THRESH_BINARY, 11, 2)
    # é™å™ªå¤„ç†
    denoised = cv2.fastNlMeansDenoising(thresh, h=10)
    return denoised



def fdetect_wechat_theme(image):
    """
    æ£€æµ‹å¾®ä¿¡ä¸»é¢˜æ¨¡å¼ï¼ˆæ·±è‰²/æµ…è‰²ï¼‰
    Returns: 'dark' or 'light'
    """
    height, width = image.shape[:2]
    
    # å–æ ·å¤šä¸ªèƒŒæ™¯åŒºåŸŸæ¥åˆ¤æ–­ä¸»é¢˜
    sample_regions = [
        (int(width * 0.4), int(height * 0.2), 50, 50),  # ä¸Šæ–¹ä¸­å¤®
        (int(width * 0.6), int(height * 0.5), 50, 50),  # ä¸­é—´å³ä¾§
        (int(width * 0.5), int(height * 0.8), 50, 50),  # ä¸‹æ–¹ä¸­å¤®
    ]
    
    avg_brightness = 0
    sample_count = 0
    
    for x, y, w, h in sample_regions:
        if x + w < width and y + h < height:
            region = image[y:y+h, x:x+w]
            gray_region = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)
            avg_brightness += np.mean(gray_region)
            sample_count += 1
    
    if sample_count > 0:
        avg_brightness /= sample_count
        
    # é˜ˆå€¼åˆ¤æ–­æ·±è‰²/æµ…è‰²æ¨¡å¼
    theme = 'dark' if avg_brightness < 100 else 'light'
    print(f"ğŸ¨ æ£€æµ‹åˆ°ä¸»é¢˜: {theme} æ¨¡å¼ (äº®åº¦: {avg_brightness:.1f})")
    return theme

def fget_theme_colors(theme):
    """æ ¹æ®ä¸»é¢˜è¿”å›æ¶ˆæ¯æ°”æ³¡é¢œè‰²"""
    if theme == 'dark':
        # æ·±è‰²æ¨¡å¼é¢œè‰²
        incoming_colors = [
            (45, 45, 45),    # æ·±ç°è‰²æ°”æ³¡
            (55, 55, 55),    # ç¨äº®çš„æ·±ç°
            (65, 65, 65),    # å¦ä¸€ç§æ·±ç°å˜ä½“
            (40, 40, 40),    # æ›´æ·±çš„ç°è‰²
        ]
        outgoing_color = (76, 148, 83)  # ç»¿è‰²æ°”æ³¡ï¼ˆæ·±æµ…æ¨¡å¼åŸºæœ¬ç›¸åŒï¼‰
        
    else:  # light mode
        incoming_colors = [
            (255, 255, 255), # ç™½è‰²æ°”æ³¡
            (245, 245, 245), # æµ…ç°æ°”æ³¡
            (250, 250, 250), # åç™½æ°”æ³¡
        ]
        outgoing_color = (169, 234, 122)  # æµ…ç»¿æ°”æ³¡
    
    return incoming_colors, outgoing_color

def fextract_messages_by_theme(image, theme='light', tolerance=30):
    """
    æ ¹æ®å¾®ä¿¡ä¸»é¢˜æå–æ¶ˆæ¯åŒºåŸŸ
    Returns: (incoming_regions, outgoing_regions)
    """
    incoming_colors, outgoing_color = get_theme_colors(theme)
    
    incoming_regions = []
    outgoing_regions = []
    
    # æŸ¥æ‰¾æ¥æ”¶æ¶ˆæ¯åŒºåŸŸï¼ˆæ·±è‰²æ¨¡å¼ï¼šæ·±ç°ï¼Œæµ…è‰²æ¨¡å¼ï¼šç™½è‰²ï¼‰
    for target_color in incoming_colors:
        regions = find_color_regions(image, target_color, tolerance)
        incoming_regions.extend(regions)
    
    # æŸ¥æ‰¾å‘é€æ¶ˆæ¯åŒºåŸŸï¼ˆç»¿è‰²æ°”æ³¡ï¼‰
    outgoing_regions = find_color_regions(image, outgoing_color, tolerance)
    
    return incoming_regions, outgoing_regions

def ffind_color_regions(image, target_color, tolerance=30):
    """
    åœ¨å›¾åƒä¸­æŸ¥æ‰¾ç‰¹å®šé¢œè‰²çš„åŒºåŸŸ
    Returns: list of (x, y, w, h) bounding boxes
    """
    target_color = np.array(target_color)
    
    # åˆ›å»ºé¢œè‰²æ©ç 
    lower = np.array([max(0, c - tolerance) for c in target_color])
    upper = np.array([min(255, c + tolerance) for c in target_color])
    
    mask = cv2.inRange(image, lower, upper)
    
    # æŸ¥æ‰¾è½®å»“
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    regions = []
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        
        # è¿‡æ»¤å°åŒºåŸŸï¼ˆå™ªå£°ï¼‰
        if w > 50 and h > 20:
            regions.append((x, y, w, h))
    
    return regions

def fget_chat_messages(screenshot_path):
    """æ•è·å¹¶è§£æå¾®ä¿¡æ¶ˆæ¯ï¼ˆæ”¯æŒæ·±è‰²/æµ…è‰²æ¨¡å¼ï¼‰"""
    total_start = time.time()
    time_stats = {
        'total': 0,
        'image_load': 0,
        'theme_detect': 0,
        'region_detect': 0,
        'ocr_process': 0,
        'text_filter': 0
    }
    result = {'white': []}  # ä¿æŒåŸå§‹æ ¼å¼å…¼å®¹æ€§
    
    try:
        # å›¾åƒåŠ è½½è€—æ—¶
        img_load_start = time.time()
        image = cv2.imread('./' + screenshot_path)
        if image is None:
            print(f"âŒ æ— æ³•åŠ è½½å›¾åƒ: {screenshot_path}")
            return result

        time_stats['image_load'] = time.time() - img_load_start

        # ä¸»é¢˜æ£€æµ‹è€—æ—¶
        theme_start = time.time()
        theme = detect_wechat_theme(image)
        time_stats['theme_detect'] = time.time() - theme_start

        # æ¶ˆæ¯åŒºåŸŸæ£€æµ‹è€—æ—¶
        region_start = time.time()
        incoming_regions, outgoing_regions = extract_messages_by_theme(image, theme)
        time_stats['region_detect'] = time.time() - region_start
        
        print(f"ğŸ“± æ‰¾åˆ° {len(incoming_regions)} ä¸ªæ¥æ”¶æ¶ˆæ¯åŒºåŸŸ, {len(outgoing_regions)} ä¸ªå‘é€æ¶ˆæ¯åŒºåŸŸ")

        # OCRå¤„ç†è€—æ—¶
        ocr_start = time.time()
        
        # å¤„ç†æ¥æ”¶æ¶ˆæ¯ï¼ˆè¿™æ˜¯æˆ‘ä»¬ä¸»è¦å…³å¿ƒçš„ï¼‰
        clean_texts = []
        for i, (x, y, w, h) in enumerate(incoming_regions):
            try:
                # è£å‰ªæ¶ˆæ¯åŒºåŸŸ
                message_region = image[y:y+h, x:x+w]
                
                # é¢„å¤„ç†
                processed_region = preprocess_for_ocr(message_region)
                
                # OCRè¯†åˆ«
                words_result = OCR_READER.readtext(processed_region)
                
                # æå–æ–‡æœ¬
                region_text = ''
                for detection in words_result:
                    text = detection[1].strip()
                    confidence = detection[2]
                    
                    if text and confidence > 0.5:  # è¿‡æ»¤ä½ç½®ä¿¡åº¦
                        region_text += text
                        
                if region_text:
                    clean_texts.append(region_text)
                    print(f"ğŸ“ åŒºåŸŸ {i+1}: '{region_text[:30]}{'...' if len(region_text) > 30 else ''}'")
            
            except Exception as e:
                print(f"âŒ åŒºåŸŸ {i+1} OCRé”™è¯¯: {e}")
        
        # å–æœ€æ–°ï¼ˆæœ€ä¸‹æ–¹ï¼‰çš„æ¶ˆæ¯
        if clean_texts:
            # å‡è®¾æœ€åä¸€ä¸ªåŒºåŸŸæ˜¯æœ€æ–°æ¶ˆæ¯
            result['white'] = [clean_texts[-1]]
            print(f"âœ… æå–åˆ°æœ€æ–°æ¶ˆæ¯: '{clean_texts[-1][:50]}{'...' if len(clean_texts[-1]) > 50 else ''}'")
        
        time_stats['ocr_process'] = time.time() - ocr_start
        time_stats['total'] = time.time() - total_start

        # æ‰“å°è€—æ—¶åˆ†æ
        print("\n[å¢å¼ºæ€§èƒ½åˆ†æ]")
        print(f"æ€»è€—æ—¶: {time_stats['total']:.3f}s")
        print(f"å›¾åƒåŠ è½½: {time_stats['image_load'] * 1000:.1f}ms ({time_stats['image_load'] / time_stats['total']:.1%})")
        print(f"ä¸»é¢˜æ£€æµ‹: {time_stats['theme_detect'] * 1000:.1f}ms")
        print(f"åŒºåŸŸæ£€æµ‹: {time_stats['region_detect'] * 1000:.1f}ms")
        print(f"OCRå¤„ç†: {time_stats['ocr_process'] * 1000:.1f}ms ({time_stats['ocr_process'] / time_stats['total']:.1%})")

        return result

    except Exception as e:
        print(f"æ¶ˆæ¯æ•è·å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return result


# ========== ä¸»ç¨‹åº ==========
if __name__ == "__main__":
    total_start = time.time()
    image_path = '../pic/screenshots/wechat_20250224_224615.png'
    image = cv2.imread(image_path)
    print(image.shape )
    result = get_chat_messages(image_path)
    # y = recognize_green_bottom(image_path)
    pprint(result)
    total= time.time() - total_start
    pprint(total)
